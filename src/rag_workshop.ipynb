{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a36ff228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded configuration from: /Users/harsh.pandey/Desktop/GenAI/rag-demo/.env\n",
      "‚úÖ Azure Configured. Key: 97e83...******\n",
      "‚úÖ Azure OpenAI Model: gpt-5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "env_path = os.path.join('..', '.env')\n",
    "\n",
    "# 1. Loading the variables\n",
    "if os.path.exists(env_path):\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "    print(f\"‚úÖ Loaded configuration from: {os.path.abspath(env_path)}\")\n",
    "else:\n",
    "    print(\"‚ùå Error: .env file not found in project root.\")\n",
    "\n",
    "# 2. Verifying Credentials\n",
    "required_vars = [\n",
    "    \"AZURE_OPENAI_API_KEY\", \n",
    "    \"AZURE_OPENAI_ENDPOINT\", \n",
    "    \"AZURE_OPENAI_API_VERSION\", \n",
    "    \"AZURE_OPENAI_MODEL\",\n",
    "]\n",
    "\n",
    "missing = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing:\n",
    "    print(f\"‚ùå Missing environment variables: {missing}\")\n",
    "else:\n",
    "    key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    print(f\"‚úÖ Azure Configured. Key: {key[:5]}...******\")\n",
    "    print(f\"‚úÖ Azure OpenAI Model: {os.getenv('AZURE_OPENAI_MODEL')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a29ce31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è File already exists locally.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os \n",
    "\n",
    "# 1. Configuration\n",
    "pdf_url = \"https://globalwellnessinstitute.org/wp-content/uploads/2023/12/NUTRITION_4_HEALTH_SPAN_GWI_final_202301210_hi-res.pdf\"\n",
    "\n",
    "output_folder = \"../pdf\"\n",
    "\n",
    "file_path = os.path.join(output_folder, \"nutrition_healthspan.pdf\")\n",
    "\n",
    "# 2. Download if not exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Downloading PDF from {pdf_url}...\")\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(pdf_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"‚úÖ Download complete.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to download. Status: {response.status_code}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è File already exists locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d53ef965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF... (This reads the file)\n",
      "   Loaded 88 pages.\n",
      "Splitting document into chunks...\n",
      "‚úÖ Created 127 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "print(\"Loading PDF... (This reads the file)\")\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "print(f\"   Loaded {len(docs)} pages.\")\n",
    "\n",
    "# Spliting Configuration\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,    # Characters per chunk\n",
    "    chunk_overlap=200   # Overlap to preserve context\n",
    ")\n",
    "\n",
    "print(\"Splitting document into chunks...\")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"‚úÖ Created {len(splits)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c4993ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öóÔ∏è  Embedding chunks using: None...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751206f8f72a4bf583c50bb7356fd6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector Store created successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "# 1. Configuring Embedding Model\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\"),    \n",
    "    chunk_size=100,\n",
    "    show_progress_bar=True,\n",
    "    max_retries=20,\n",
    "    retry_min_seconds=2\n",
    ")\n",
    "\n",
    "print(f\"‚öóÔ∏è  Embedding chunks using: {os.getenv('AZURE_EMBEDDING_DEPLOYMENT')}...\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "print(\"‚úÖ Vector Store created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1316f89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dea2f6525e459bb3c1230a17099491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'apple'\n",
      "Vector Dimensions: 1536\n",
      "Type: <class 'list'>\n",
      "First 10 numbers: [0.01764063909649849, -0.016817327588796616, -0.04184354469180107, 0.019008787348866463, -0.0018100723391398787, -0.026902882382273674, 0.007264504674822092, 0.02287108078598976, -0.01952940970659256, -0.016732575371861458]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Sample embedding\n",
    "sample_word = \"apple\"\n",
    "vector = embeddings.embed_query(sample_word)\n",
    "\n",
    "print(f\"Word: '{sample_word}'\")\n",
    "print(f\"Vector Dimensions: {len(vector)}\") # Should be 1536 for OpenAI models\n",
    "print(f\"Type: {type(vector)}\")\n",
    "print(f\"First 10 numbers: {vector[:10]}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33167cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching PDF for: 'My stomach hurts after eating dairy. Do I have Celiac disease or IBS?'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84f0511af1b4f26843e316525c5a1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Asking Azure gpt-5...\n",
      "\n",
      "--- Answer ---\n",
      "I don't know. The context does not specify whether stomach pain after eating dairy indicates celiac disease or IBS.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os \n",
    "\n",
    "# 1. Setup Azure Client\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "deployment = os.getenv(\"AZURE_DEPLOYMENT\")\n",
    "\n",
    "# 2. Define Question\n",
    "user_question = input(\"Enter your question: \")\n",
    "\n",
    "# 3. Retrieve Context (Manually)\n",
    "print(f\"üîç Searching PDF for: '{user_question}'...\")\n",
    "relevant_docs = vectorstore.similarity_search(user_question, k=3)\n",
    "\n",
    "# Join the retrieved text into one big string\n",
    "context_data = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "# 4. Preparing the Prompt\n",
    "system_prompt = \"\"\"You are a strict assistant.\n",
    "Your ONLY task is to answer the user's question based on the provided context below.\n",
    "- Do NOT use your internal knowledge.\n",
    "- Do NOT make up facts.\n",
    "- If the answer is not explicitly written in the context, you MUST say \"I don't know\".\n",
    "- Do not try to be helpful by adding outside information.\n",
    "\"\"\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "Context:\n",
    "{context_data}\n",
    "\n",
    "Question: \n",
    "{user_question}\n",
    "\"\"\"\n",
    "\n",
    "# 5. Call GPT-5 \n",
    "print(f\"ü§ñ Asking Azure {os.getenv('AZURE_OPENAI_MODEL')}...\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6. Output\n",
    "print(\"\\n--- Answer ---\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
